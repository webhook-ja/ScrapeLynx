# ğŸ›ï¸ TEMU Scraper - Sistema Completo

Sistema avanzado de scraping de productos de Temu con:
- ğŸ¤– **Scraping anti-bot** con Crawl4AI + IA
- ğŸ”— **GeneraciÃ³n automÃ¡tica** de links de afiliado
- ğŸ¨ **Interfaz web** con filtros interactivos
- ğŸ”„ **API REST** para integraciÃ³n con n8n
- ğŸ’¾ **Base de datos** SQLite/PostgreSQL

---

## ğŸ”¥ CaracterÃ­sticas Completas

âœ… **Scraping anti-bot**: Evade protecciones de Temu usando Crawl4AI con stealth mode
âœ… **ExtracciÃ³n con IA**: Usa LLMs para extraer datos estructurados sin selectores CSS
âœ… **Links de afiliado**: Genera automÃ¡ticamente tus links de referido
âœ… **Filtros avanzados**: Rating, reviews, ventas, precio, categorÃ­a
âœ… **API REST**: FastAPI con endpoints para bÃºsqueda y gestiÃ³n
âœ… **Frontend web**: Interfaz grÃ¡fica con Tailwind CSS
âœ… **IntegraciÃ³n n8n**: Workflows listos para importar
âœ… **Base de datos**: SQLite (desarrollo) o PostgreSQL (producciÃ³n)
âœ… **Scripts de instalaciÃ³n**: Setup automÃ¡tico para Windows/Linux/Mac

---

## ğŸ“ Estructura del Proyecto

```
temu_scraper/
â”œâ”€â”€ scraper.py              # Motor de scraping (Crawl4AI + LLM)
â”œâ”€â”€ api.py                  # API REST (FastAPI)
â”œâ”€â”€ database.py             # Sistema de base de datos
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ .env.example           # Template de configuraciÃ³n
â”‚
â”œâ”€â”€ frontend/              # Interfaz web
â”‚   â”œâ”€â”€ index.html        # Frontend HTML
â”‚   â””â”€â”€ app.js            # JavaScript
â”‚
â”œâ”€â”€ n8n_workflows/        # Workflows de n8n
â”‚   â”œâ”€â”€ temu_scraper_workflow.json
â”‚   â””â”€â”€ README_N8N.md
â”‚
â”œâ”€â”€ results/              # Resultados guardados (JSON)
â”‚
â””â”€â”€ Scripts de instalaciÃ³n:
    â”œâ”€â”€ install.bat       # Windows
    â”œâ”€â”€ install.sh        # Linux/Mac
    â”œâ”€â”€ start_api.bat     # Iniciar API (Windows)
    â”œâ”€â”€ start_api.sh      # Iniciar API (Linux/Mac)
    â”œâ”€â”€ test_scraper.bat  # Probar scraper (Windows)
    â””â”€â”€ test_scraper.sh   # Probar scraper (Linux/Mac)
```

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Windows

```bash
# 1. Clonar/descargar el proyecto
cd temu_scraper

# 2. Ejecutar instalador automÃ¡tico
install.bat

# 3. Editar .env con tus credenciales
notepad .env

# 4. Iniciar la API
start_api.bat

# 5. Abrir frontend
start_frontend.bat
```

### Linux/Mac

```bash
# 1. Clonar/descargar el proyecto
cd temu_scraper

# 2. Dar permisos a los scripts
chmod +x *.sh

# 3. Ejecutar instalador automÃ¡tico
./install.sh

# 4. Editar .env con tus credenciales
nano .env

# 5. Iniciar la API
./start_api.sh

# 6. Abrir frontend/index.html en navegador
```

---

## ğŸ“¦ InstalaciÃ³n Manual

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Instalar navegadores de Playwright

```bash
playwright install chromium
```

### 3. Configurar variables de entorno

Copia el archivo `.env.example` a `.env`:

```bash
cp .env.example .env
```

Edita `.env` y agrega:
- Tu **ID de afiliado de Temu**
- Tu **API Key de OpenAI** (o usa Ollama local)

### 4. Inicializar base de datos

```bash
python database.py
```

---

## ğŸš€ Uso

### BÃºsqueda bÃ¡sica

```python
import asyncio
from scraper import scrape_temu_search

async def main():
    results = await scrape_temu_search(
        search_query="wireless earbuds",
        max_products=20
    )
    print(results)

asyncio.run(main())
```

### BÃºsqueda con filtros avanzados

```python
results = await scrape_temu_search(
    search_query="smartphone",
    max_products=30,
    min_rating=4.5,        # MÃ­nimo 4.5 estrellas
    min_reviews=500,       # MÃ­nimo 500 reviews
    min_sales=1000,        # MÃ­nimo 1000 ventas
    price_min=50.0,        # Precio mÃ­nimo $50
    price_max=300.0        # Precio mÃ¡ximo $300
)
```

### Scrape de producto individual

```python
from scraper import scrape_single_product

result = await scrape_single_product(
    product_url="https://www.temu.com/example-product.html"
)
```

---

## ğŸ§ª Pruebas

Ejecuta el script de prueba:

```bash
python scraper.py
```

Esto buscarÃ¡ "wireless earbuds" con filtros y guardarÃ¡ los resultados en `temu_search_results.json`.

---

## ğŸ“Š Estructura de Datos

### Producto

```json
{
  "title": "Auriculares Bluetooth TWS",
  "price": 15.99,
  "original_price": 39.99,
  "discount_percentage": 60,
  "rating": 4.7,
  "reviews_count": 1523,
  "sales_count": 5420,
  "image_url": "https://...",
  "product_url": "https://www.temu.com/...",
  "affiliate_link": "https://www.temu.com/...?_x_ads_channel=affiliate&_x_ads_sub_channel=YOUR_ID",
  "category": "Electronics"
}
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar modelo LLM

En `scraper.py`, modifica:

```python
# Usar GPT-4o (mÃ¡s preciso, mÃ¡s caro)
LLM_PROVIDER = "openai/gpt-4o"

# Usar GPT-4o-mini (mÃ¡s barato, rÃ¡pido)
LLM_PROVIDER = "openai/gpt-4o-mini"

# Usar Ollama local (GRATIS, pero necesitas correr Ollama)
LLM_PROVIDER = "ollama/llama2"
```

### Ajustar anti-bot protection

En `CrawlerRunConfig`:

```python
config = CrawlerRunConfig(
    magic=True,              # Activa anti-bot automÃ¡tico
    simulate_user=True,      # Simula movimiento de mouse, etc.
    override_navigator=True, # Falsifica propiedades del navegador
    delay_before_return_html=5.0,  # Esperar mÃ¡s tiempo
)
```

---

## ğŸ”— IntegraciÃ³n con n8n

### Importar Workflow

1. Abre n8n
2. Importa `n8n_workflows/temu_scraper_workflow.json`
3. Configura credenciales (Google Sheets, Telegram)
4. Actualiza la URL de la API
5. Lee la documentaciÃ³n completa en `n8n_workflows/README_N8N.md`

### Endpoints de la API

```
POST /api/search          - BÃºsqueda de productos
POST /api/product         - Scrape producto individual
POST /api/affiliate       - Generar link de afiliado
GET  /api/results         - Listar resultados guardados
GET  /api/results/{file}  - Obtener resultado especÃ­fico

POST /webhook/n8n/search  - Webhook especial para n8n
```

DocumentaciÃ³n completa: `http://localhost:8000/docs`

---

## ğŸ’¾ Base de Datos

### SQLite (Desarrollo)

Por defecto, usa SQLite local (`temu_products.db`):

```python
# .env
DATABASE_TYPE=sqlite
DATABASE_URL=sqlite:///temu_products.db
```

### PostgreSQL (ProducciÃ³n)

Para producciÃ³n, usa PostgreSQL:

```python
# .env
DATABASE_TYPE=postgresql
DATABASE_URL=postgresql://user:password@localhost:5432/temu_db
```

### Funciones Disponibles

```python
from database import db

# Guardar productos
await db.save_product(product_data)
await db.save_products_batch([product1, product2])

# Buscar productos
products = await db.search_products(
    query="earbuds",
    min_rating=4.5,
    limit=50
)

# EstadÃ­sticas
stats = await db.get_stats()
```

---

## ğŸ¨ Frontend Web

### Usar la Interfaz

1. Inicia la API: `start_api.bat` o `./start_api.sh`
2. Abre `frontend/index.html` en tu navegador
3. Configura filtros de bÃºsqueda
4. Click en "Buscar Productos"
5. Copia links de afiliado con un click

### CaracterÃ­sticas del Frontend

- âœ… BÃºsqueda en tiempo real
- âœ… Filtros interactivos (rating, reviews, ventas, precio)
- âœ… Vista de productos en grid responsive
- âœ… EstadÃ­sticas automÃ¡ticas
- âœ… Copiar link de afiliado
- âœ… Vista previa de imÃ¡genes
- âœ… Indicadores de descuentos

---

## ğŸ“Š API Endpoints (Detalle)

### BÃºsqueda de Productos

```bash
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "search_query": "wireless earbuds",
    "max_products": 20,
    "min_rating": 4.0,
    "min_reviews": 100,
    "min_sales": 0,
    "price_min": 0,
    "price_max": 999999
  }'
```

### Producto Individual

```bash
curl -X POST http://localhost:8000/api/product \
  -H "Content-Type: application/json" \
  -d '{
    "product_url": "https://www.temu.com/product-xyz.html"
  }'
```

### Generar Link de Afiliado

```bash
curl -X POST http://localhost:8000/api/affiliate \
  -H "Content-Type: application/json" \
  -d '{
    "product_url": "https://www.temu.com/product-xyz.html",
    "affiliate_id": "YOUR_ID"
  }'
```

---

## âš ï¸ Notas Importantes

1. **Rate limiting**: No hagas scraping masivo. Usa delays entre requests (configurado en 2-3 segundos)
2. **TÃ©rminos de servicio**: Respeta los TOS de Temu
3. **Proxies**: Para scraping intensivo, considera usar proxies rotativos
4. **Costos LLM**: Si usas OpenAI, ten en cuenta los costos por request (~$0.001-0.01 por bÃºsqueda)
5. **CachÃ©**: La base de datos cachea resultados para evitar scraping repetido
6. **Anti-bot**: Crawl4AI incluye stealth mode, pero Temu puede bloquearte si haces muchos requests

---

## ğŸ› Troubleshooting

### Error: "Could not find module 'crawl4ai'"

**SoluciÃ³n**: Instala las dependencias
```bash
pip install -r requirements.txt
playwright install chromium
```

### Error: "OPENAI_API_KEY not found"

**SoluciÃ³n**: Configura tu `.env`
```bash
cp .env.example .env
# Edita .env y agrega tu API key
```

### Error: "Connection refused localhost:8000"

**SoluciÃ³n**: AsegÃºrate de que la API estÃ© corriendo
```bash
python api.py
```

### Scraping muy lento

**SoluciÃ³n**: Reduce el delay en `scraper.py`
```python
config = CrawlerRunConfig(
    delay_before_return_html=2.0  # Cambiar de 3.0 a 2.0
)
```

### Temu bloqueÃ³ mi IP

**SoluciÃ³n**:
1. Espera 30 minutos
2. Usa VPN o proxies rotativos
3. Reduce la frecuencia de scraping

---

## ğŸ“ TO-DO / Roadmap

- [x] Scraper con Crawl4AI + LLM
- [x] API REST con FastAPI
- [x] Frontend con filtros interactivos
- [x] IntegraciÃ³n n8n
- [x] Sistema de base de datos
- [x] Scripts de instalaciÃ³n
- [ ] Sistema de cachÃ© (Redis)
- [ ] Soporte para proxies rotativos
- [ ] Modo batch (scrapear mÃºltiples bÃºsquedas)
- [ ] Dashboard de estadÃ­sticas avanzadas
- [ ] Sistema de alertas (precio/stock)
- [ ] Exportar a CSV/Excel
- [ ] Docker Compose para deployment

---

## ğŸ¤ Contribuciones

Creado para automatizar bÃºsqueda de productos en Temu con links de afiliado.

**Dev: Jorge** ğŸ”¥
